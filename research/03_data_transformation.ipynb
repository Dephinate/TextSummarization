{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation: COnvert Data To Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from TextSummarizer.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dephinate/ASU/TextSummarization'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    tokenizer_name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextSummarizer.utils.common import create_directories\n",
    "# Method to read Data Transformation Configuration\n",
    "def get_data_transformation_config(self):\n",
    "    config = self.config.data_transformation\n",
    "\n",
    "    create_directories(config.root_dir)\n",
    "\n",
    "    data_transformation_config = DataTransformationConfig(\n",
    "        root_dir=config.root_dir,\n",
    "        data_path=config.data_path,\n",
    "        tokenizer_name=config.tokenizer_name\n",
    "    )\n",
    "    return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class DataTransformation \n",
    "* Takes Data Transformation Config\n",
    "* Initialize pre-trained tokenizer\n",
    "* tokanize model input\n",
    "* tokenize model output, these are nothing but labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextSummarizer.config.configurations import ConfigurationManager\n",
    "from TextSummarizer.entity import DataTransformationConfig\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig) -> None:\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)\n",
    "\n",
    "# Method to tokenize input and output\n",
    "    def convert_examples_to_features(self, example_batch):\n",
    "        '''\n",
    "        Converts input to embeddings\n",
    "        Input: Document\n",
    "        Output: Dictionary of Input Encodings, Attention Masks, Target Encoding\n",
    "        '''\n",
    "        input_encodings = self.tokenizer(text=example_batch['dialogue'], max_length= 1024, truncation=True)\n",
    "\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            target_encodings = self.tokenizer(text=example_batch['summary'], max_length=128, truncation=True)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encodings['input_ids'], \n",
    "            'attention_mask': input_encodings['attention_mask'],\n",
    "            'labels': target_encodings['input_ids']\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize object of Config Manager\n",
    "# Get DataTransformation COnfigurations\n",
    "# Use those configurations to intialize Tranformation component\n",
    "\n",
    "from TextSummarizer.config.configurations import ConfigurationManager\n",
    "from TextSummarizer.components.data_transformation import DataTransformation\n",
    "\n",
    "\n",
    "class DataTransformationTrainingPipeline:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(\n",
    "            config=data_transformation_config)\n",
    "        data_transformation.convert()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
